name: Deploy to EC2 üöÄ

on:
  push:
    branches:
      - main
  workflow_dispatch:

# Add concurrency to ensure only one deployment runs at a time
concurrency:
  group: production
  cancel-in-progress: false

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      NEXT_PUBLIC_JIRA_URL: https://***REMOVED***.atlassian.net

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: üîÑ Update version
        id: update_version
        run: |
          # Read current version
          CURRENT_VERSION=$(node -p "require('./package.json').version")
          echo "Current version: $CURRENT_VERSION"

          # Split version into parts
          IFS='.' read -r -a VERSION_PARTS <<< "$CURRENT_VERSION"
          MAJOR="${VERSION_PARTS[0]}"
          MINOR="${VERSION_PARTS[1]}"
          PATCH="${VERSION_PARTS[2]}"

          # Increment patch version
          NEW_PATCH=$((PATCH + 1))
          NEW_VERSION="$MAJOR.$MINOR.$NEW_PATCH"
          echo "New version: $NEW_VERSION"

          # Update package.json
          node -e "
            const fs = require('fs');
            const package = require('./package.json');
            package.version = '$NEW_VERSION';
            fs.writeFileSync('./package.json', JSON.stringify(package, null, 2) + '\n');
          "

          # Configure git
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"

          # Commit and push changes
          git add package.json
          git commit -m "chore: bump version to $NEW_VERSION [skip ci]"
          git push

          # Set output for later steps
          echo "version=${NEW_VERSION}" >> $GITHUB_OUTPUT
          echo "release_tag=v${NEW_VERSION}" >> $GITHUB_OUTPUT
          echo "release_name=Release v${NEW_VERSION}" >> $GITHUB_OUTPUT

      - name: üè∑Ô∏è Get version from package.json
        id: package_version
        run: |
          VERSION=${{ steps.update_version.outputs.version }}
          RELEASE_TAG=${{ steps.update_version.outputs.release_tag }}
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "release_tag=${RELEASE_TAG}" >> $GITHUB_OUTPUT
          echo "release_name=Release ${RELEASE_TAG}" >> $GITHUB_OUTPUT
          echo "Using version: ${VERSION}"

      - name: üåç Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-2

      - name: üîë Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: üèóÔ∏è Build and push Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ***REMOVED***/timesheet
          VERSION: ${{ steps.package_version.outputs.version }}
          RELEASE_TAG: ${{ steps.package_version.outputs.release_tag }}
        run: |
          echo "::group::üê≥ Docker Build Process"
          echo "üì¶ Building Docker image..."

          # Check available disk space before build
          echo "Available disk space before build:"
          df -h

          # Enable BuildKit with improved layer caching and better space efficiency
          DOCKER_BUILDKIT=1 docker build \
                --progress=plain \
                --no-cache \
                --build-arg DATABASE_URL="file:./dev.db" \
                --build-arg NEXT_PUBLIC_JIRA_URL=${{ env.NEXT_PUBLIC_JIRA_URL }} \
                --build-arg NEXT_TELEMETRY_DISABLED=1 \
                --build-arg NODE_ENV=production \
                -t $ECR_REGISTRY/$ECR_REPOSITORY:${RELEASE_TAG} \
                -t $ECR_REGISTRY/$ECR_REPOSITORY:latest . || {
              echo "::error::Docker build failed"
              echo "Checking disk space after failure:"
              df -h
              docker system df
              exit 1
            }

          # Show available disk space after build
          echo "Available disk space after build:"
          df -h

          # Show image details after successful build
          echo "üìã Image details:"
          docker images $ECR_REGISTRY/$ECR_REPOSITORY:${RELEASE_TAG} --format "ID: {{.ID}}\nSize: {{.Size}}\nCreated: {{.CreatedSince}}"
          echo "::endgroup::"

          echo "::group::‚¨ÜÔ∏è Docker Push Process"
          echo "‚¨ÜÔ∏è Pushing image to ECR..."
          if ! docker push $ECR_REGISTRY/$ECR_REPOSITORY:${RELEASE_TAG} || ! docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest; then
            echo "::error::Failed to push Docker image to ECR"
            exit 1
          fi

          # Show push summary
          echo "üìä Push summary:"
          docker image inspect $ECR_REGISTRY/$ECR_REPOSITORY:${RELEASE_TAG} --format 'Repository: {{.RepoTags}}\nSize: {{.Size}} bytes\nLayers: {{len .RootFS.Layers}}'
          echo "::endgroup::"

      - name: üöÄ Deploy to EC2
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          EC2_HOST: ${{ vars.EC2_HOST }}
          EC2_USERNAME: ubuntu
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ***REMOVED***/timesheet
          VERSION: ${{ steps.package_version.outputs.version }}
          RELEASE_TAG: ${{ steps.package_version.outputs.release_tag }}
        run: |
          echo "::group::üîë SSH Setup"
          echo "Setting up SSH keys..."
          echo "$PRIVATE_KEY" > private_key.pem
          chmod 600 private_key.pem
          echo "::endgroup::"

          echo "::group::üìù Deployment Script Creation"
          echo "Creating deployment script..."
          echo '#!/bin/bash
          echo "::group::üîë ECR Authentication"
          echo "Logging into ECR..."
          if ! aws ecr get-login-password --region ap-southeast-2 | docker login --username AWS --password-stdin ${{ steps.login-ecr.outputs.registry }}; then
            echo "::error::Failed to authenticate with ECR"
            exit 1
          fi
          echo "::endgroup::"

          echo "::group::‚¨áÔ∏è Image Pull"
          echo "Pulling new container image..."
          if ! docker pull ${{ steps.login-ecr.outputs.registry }}/***REMOVED***/timesheet:latest; then
            echo "::error::Failed to pull latest image"
            exit 1
          fi
          echo "::endgroup::"

          echo "::group::üîÑ Zero-Downtime Deployment"
          # Create Docker network if it doesn't exist
          if ! docker network inspect timesheet-network >/dev/null 2>&1; then
            echo "Creating Docker network..."
            docker network create timesheet-network
          fi

          # Check if existing container is connected to the network
          if docker ps | grep -q timesheet-app; then
            if ! docker network inspect timesheet-network | grep -q timesheet-app; then
              echo "Connecting existing container to network..."
              docker network connect timesheet-network timesheet-app
            fi
          fi

          # Generate unique name for the new container
          NEW_CONTAINER="timesheet-app-${VERSION}"
          echo "Starting new container..."

          # Ensure data directory exists with proper permissions
          DATA_DIR="/home/$USER/timesheet-data"
          echo "Creating data directory at $DATA_DIR..."
          mkdir -p $DATA_DIR

          # Copy SQLite database from the current container if it exists
          if docker ps | grep -q timesheet-app; then
            echo "Ensuring database consistency..."
            # Copy database from container to host if needed
            if docker exec timesheet-app sh -c "[ -f /app/data/dev.db ]"; then
              echo "Copying database from container to host..."
              docker cp timesheet-app:/app/data/dev.db $DATA_DIR/dev.db
              # Create a backup of the database
              cp $DATA_DIR/dev.db $DATA_DIR/dev.db.backup
            fi
          fi

          # Start new container with the new version
          if ! docker run -d \
            --name=$NEW_CONTAINER \
            --restart=always \
            --network=timesheet-network \
            -v $DATA_DIR:/app/data \
            -e NEXT_PUBLIC_JIRA_URL='${{ env.NEXT_PUBLIC_JIRA_URL }}' \
            -e APP_VERSION='${VERSION}' \
            -e JIRA_API_TOKEN='${{ secrets.JIRA_API_TOKEN }}' \
            -e JIRA_USER_EMAIL='malin.malliyawadu@***REMOVED***.com' \
            -e JIRA_HOST='***REMOVED***.atlassian.net' \
            -e IPAYROLL_API_URL='https://api.ipayroll.com' \
            -e IPAYROLL_API_KEY='${{ secrets.IPAYROLL_API_KEY }}' \
            -e IPAYROLL_COMPANY_ID='${{ secrets.IPAYROLL_COMPANY_ID }}' \
            '${{ steps.login-ecr.outputs.registry }}/***REMOVED***/timesheet:latest'; then
            echo "::error::Failed to start new container"
            exit 1
          fi

          # Give the container some time to initialize before health checks
          echo "Waiting for container to initialize (10 seconds)..."
          sleep 10

          # Verify the container is still running after initial startup
          if ! docker ps | grep -q $NEW_CONTAINER; then
            echo "::error::Container failed to stay running after initial startup"
            docker logs $NEW_CONTAINER
            # Restore database backup if it exists
            if [ -f "$DATA_DIR/dev.db.backup" ]; then
              echo "Restoring database backup..."
              mv "$DATA_DIR/dev.db.backup" "$DATA_DIR/dev.db"
            fi
            exit 1
          fi

          # Wait for the new container to be ready
          echo "Waiting for new container to be ready..."
          HEALTH_CHECK_RETRIES=60  # Increased retries for log check
          HEALTH_CHECK_DELAY=2

          for i in $(seq 1 $HEALTH_CHECK_RETRIES); do
            # First check if container is still running
            if ! docker ps | grep -q $NEW_CONTAINER; then
              echo "::error::Container stopped during health check"
              docker logs $NEW_CONTAINER
              # Restore database backup if it exists
              if [ -f "$DATA_DIR/dev.db.backup" ]; then
                echo "Restoring database backup..."
                mv "$DATA_DIR/dev.db.backup" "$DATA_DIR/dev.db"
              fi
              exit 1
            fi
            
            # Check for the specific log message indicating the app is ready
            if docker logs $NEW_CONTAINER 2>&1 | grep -q "- Local:.*http://localhost:3000"; then
              echo "‚úÖ Application is ready! Found startup message in logs."
              break
            fi
            
            if [ $i -eq $HEALTH_CHECK_RETRIES ]; then
              echo "::error::New container failed to become ready within the timeout period"
              echo "Last 50 lines of container logs:"
              docker logs $NEW_CONTAINER --tail 50
              docker rm -f $NEW_CONTAINER
              # Restore database backup if it exists
              if [ -f "$DATA_DIR/dev.db.backup" ]; then
                echo "Restoring database backup..."
                mv "$DATA_DIR/dev.db.backup" "$DATA_DIR/dev.db"
              fi
              exit 1
            fi
            
            echo "Waiting for application to be ready... ($i/$HEALTH_CHECK_RETRIES)"
            sleep $HEALTH_CHECK_DELAY
          done

          # Double-check that the application is responding to HTTP requests
          echo "Verifying application responds to HTTP requests..."
          if ! docker exec $NEW_CONTAINER curl -s --max-time 5 http://localhost:3000 >/dev/null; then
            echo "::warning::Application is not responding to HTTP requests despite startup message"
            echo "Continuing anyway as the startup message was found..."
          else
            echo "‚úÖ Application is responding to HTTP requests!"
          fi

          # Update Nginx configuration to point to the new container
          echo "Updating Nginx configuration..."

          # Get the IP address of the new container
          NEW_CONTAINER_IP=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $NEW_CONTAINER)

          # Update the existing Nginx configuration
          sudo tee /etc/nginx/conf.d/timesheet.conf > /dev/null << EOF
          server {
              listen 80;
              server_name _;
              
              location / {
                  proxy_pass http://$NEW_CONTAINER_IP:3000;
                  proxy_set_header Host \$host;
                  proxy_set_header X-Real-IP \$remote_addr;
                  proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                  proxy_set_header X-Forwarded-Proto \$scheme;
                  
                  # WebSocket support
                  proxy_http_version 1.1;
                  proxy_set_header Upgrade \$http_upgrade;
                  proxy_set_header Connection "upgrade";
                  proxy_read_timeout 86400;
              }
          }
          EOF

          # Reload Nginx configuration
          echo "Reloading Nginx configuration..."
          sudo systemctl reload nginx || sudo service nginx reload

          # Verify the new setup works
          echo "Verifying new deployment..."
          VERIFICATION_RETRIES=5
          for i in $(seq 1 $VERIFICATION_RETRIES); do
            if curl -s http://localhost >/dev/null; then
              echo "Verification successful!"
              break
            fi
            
            if [ $i -eq $VERIFICATION_RETRIES ]; then
              echo "::error::New deployment verification failed"
              # Rollback to previous container if available
              if docker ps -a | grep -q timesheet-app; then
                echo "Rolling back to previous container..."
                ORIGINAL_CONTAINER_IP=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' timesheet-app)
                sudo tee /etc/nginx/conf.d/timesheet.conf > /dev/null << EOF
          server {
              listen 80;
              server_name _;
              
              location / {
                  proxy_pass http://$ORIGINAL_CONTAINER_IP:3000;
                  proxy_set_header Host \$host;
                  proxy_set_header X-Real-IP \$remote_addr;
                  proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                  proxy_set_header X-Forwarded-Proto \$scheme;
                  
                  # WebSocket support
                  proxy_http_version 1.1;
                  proxy_set_header Upgrade \$http_upgrade;
                  proxy_set_header Connection "upgrade";
                  proxy_read_timeout 86400;
              }
          }
          EOF
                sudo systemctl reload nginx || sudo service nginx reload
                docker rm -f $NEW_CONTAINER
                # Restore database backup if it exists
                if [ -f "$DATA_DIR/dev.db.backup" ]; then
                  echo "Restoring database backup..."
                  mv "$DATA_DIR/dev.db.backup" "$DATA_DIR/dev.db"
                fi
              fi
              exit 1
            fi
            
            echo "Retrying verification... ($i/$VERIFICATION_RETRIES)"
            sleep 2
          done

          # If everything is successful, remove the old container
          echo "Deployment successful, cleaning up old container..."
          if docker ps -a | grep -q "timesheet-app$"; then
            # Remove database backup if it exists
            if [ -f "$DATA_DIR/dev.db.backup" ]; then
              echo "Removing database backup..."
              rm "$DATA_DIR/dev.db.backup"
            fi
            
            # Stop and remove the old container
            docker stop timesheet-app
            docker rm timesheet-app
          fi

          # Rename the new container to the standard name for future deployments
          docker rename $NEW_CONTAINER timesheet-app
          echo "::endgroup::"

          echo "::group::üìä System Status"
          echo "Initial disk usage:"
          docker system df
          echo "::endgroup::"

          echo "::group::üßπ Cleanup Process"
          echo "Starting cleanup process..."

          echo "Removing unused containers..."
          docker container prune -f || echo "::warning::Failed to prune containers"

          echo "Removing unused images older than 24 hours..."
          docker image prune -af --filter "until=24h" || echo "::warning::Failed to prune images"

          echo "Removing unused networks..."
          docker network prune -f || echo "::warning::Failed to prune networks"

          echo "Removing unused volumes..."
          docker volume prune -f --filter "label!=preserve=true" || echo "::warning::Failed to prune volumes"

          # Clean up system temporary files
          echo "Cleaning up temporary files..."
          sudo find /tmp -type f -mtime +7 -delete || echo "::warning::Failed to clean up /tmp"
          sudo find /var/tmp -type f -mtime +7 -delete || echo "::warning::Failed to clean up /var/tmp"

          # Clean up log files
          echo "Cleaning up old log files..."
          sudo find /var/log -type f -name "*.gz" -delete || echo "::warning::Failed to clean up compressed logs"
          sudo find /var/log -type f -name "*.1" -delete || echo "::warning::Failed to clean up rotated logs"

          # Empty trash if available
          sudo rm -rf /root/.local/share/Trash/* || echo "::warning::No trash to empty"

          # Clear package manager cache
          echo "Cleaning package cache..."
          sudo apt-get clean || echo "::warning::Failed to clean apt cache"

          echo "Final disk usage after cleanup:"
          docker system df

          echo "Available disk space:"
          df -h
          echo "::endgroup::"' > deploy.sh

          echo "::group::üì§ Script Deployment"
          echo "Copying deployment script to EC2..."
          if ! scp -i private_key.pem -o StrictHostKeyChecking=no deploy.sh $EC2_USERNAME@$EC2_HOST:~/deploy.sh; then
            echo "::error::Failed to copy deployment script to EC2"
            exit 1
          fi

          echo "Executing deployment script..."
          if ! ssh -i private_key.pem -o StrictHostKeyChecking=no $EC2_USERNAME@$EC2_HOST "chmod +x ~/deploy.sh && ~/deploy.sh"; then
            echo "::error::Deployment script execution failed"
            exit 1
          fi
          echo "::endgroup::"

          echo "::group::üßπ Cleanup"
          echo "Cleaning up local files..."
          rm private_key.pem deploy.sh
          echo "::endgroup::"

      - name: üìù Create and update deployment status
        uses: actions/github-script@v7
        env:
          VERSION: ${{ steps.package_version.outputs.version }}
          RELEASE_TAG: ${{ steps.package_version.outputs.release_tag }}
        with:
          script: |
            const version = '${{ steps.package_version.outputs.version }}';
            const releaseTag = '${{ steps.package_version.outputs.release_tag }}';

            // Create deployment
            const deployment = await github.rest.repos.createDeployment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: context.sha,
              environment: 'production',
              auto_merge: false,
              required_contexts: [],
              production_environment: true,
              description: `Deploying version ${version}`
            });

            // Update deployment status
            await github.rest.repos.createDeploymentStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              deployment_id: deployment.data.id,
              state: 'success',
              environment_url: 'https://${{ vars.EC2_HOST }}',
              log_url: `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
              description: `Successfully deployed version ${version}!`
            });

            // Create GitHub Release
            const changelog = `
            ## What's Changed
            * Automated deployment of version ${version}
            * Deployment timestamp: ${new Date().toISOString()}
            * Commit: ${context.sha}

            ## Installation
            This release has been automatically deployed to production.

            ## Additional Notes
            * Docker image tag: \`${releaseTag}\`
            * Environment: Production
            `;

            try {
              await github.rest.repos.createRelease({
                owner: context.repo.owner,
                repo: context.repo.repo,
                tag_name: releaseTag,
                name: `${releaseTag}`,
                body: changelog,
                draft: false,
                prerelease: false,
                generate_release_notes: true
              });
              console.log(`Successfully created release ${releaseTag}`);
            } catch (error) {
              if (error.status === 422) {
                console.log(`Release ${releaseTag} already exists, skipping creation`);
              } else {
                throw error;
              }
            }
